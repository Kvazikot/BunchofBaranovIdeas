  + - - - + - + - -
  + - + - + copyright by Vladimir Baranov (Kvazikot)  <br>
  + - + - + email: vsbaranov83@gmail.com  <br>
  + - + - + github: http://github.com/Kvazikot/BallPark  <br>
```
                            )            (
                           /(   (\___/)  )\
                          ( #)  \ ('')| ( #
                           ||___c\  > '__||
                           ||**** ),_/ **'|
                     .__   |'* ___| |___*'|
                      \_\  |' (    ~   ,)'|
                       ((  |' /(.  '  .)\ |
                        \\_|_/ <_ _____> \______________
                         /   '-, \   / ,-'      ______  \
                b'ger   /      (//   \\)     __/     /   \
                                            './_____/
```              
  

# Фичи которые можно реализовать.
* Можно реализовать что-то наподобии моделирования среды хищник-жертва см [1].
* Можно продолжить возиться с паркинг-слотами и прокладыванием траектории и обучать агентов парковаться.
* 

## Библиотеки машинного обучения
1.	Среда ml-agents
Это специальная среда для обучения ml-агентов. Ее можно применить для соединения Пайтона со средой Unity. При этом обеспечивается контроль обучения в TensorBoard.
https://github.com/Unity-Technologies/ml-agents


# Лабиринт в 3д (unity-проект roll a ball).
[![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/ballpark01.png)](https://youtu.be/YBzOM5-RKNE)
[![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/ballpark2.png)](https://youtu.be/2Rz0iVN7zgA)

# Модель движения машинки(unity-проект car_model).
Отдельный проект на Юнити car_model
Здесь создана динамическая модель авто, используя инструменты Unity по туториалу, который лежит в видео файлах. Управление в режиме игры пока с клавиатуры.
  
 Алгоритм планирования пути RRT.
(Входит в состав Unity-проекта car_model.)

Алгоритмическая задача: исследовать алгоритм RRT для управления чтобы обходить коллизии и проходить маршрут от начальной точки, через промежуточные и до конечной
Алгоритм Rapidly-exploring Random Trees. (см. статью PlanningforDynamicVeh-1.pdf)

# Програмный модуль rrt_planer.cs
На первом этапе можно реализовать алгоритм простого дерева без интегрирования траектории по Рунге-Кутта (как описано в LavKuf01.pdf).  Figure 2.

![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/rrt_with_integration.png)

В качестве множества препятствий можно использовать что-то похожее на этот рисунок.
В юнити это означает что нужно вместо линий нарисовать протяженные объекты типа параллепипедов.
Переход к лабиринту осуществится на поздних итерациях проекта.
На первых этапах сосредоточится на построении графа и отрисовке траектории в виде линий и не думать пока о объекте управления. Потом подключить кинематическую модель машины для расчета поворотов. Построить траектории в виде кривых. Когда будет работать алгоритм планирования пути можно будет подключать скрипты управления машиной . В качестве входа взять граф управления построенный по алгоритму RRT (rrt_planer.cs)
 

# Вопросы по алгоритмической части:
Как выбирать распределение в функции random_config.(подход goal biased или uniform)?
В функции new_state что выбирать за u скорость или угол поворота колес, и то и другое?
Из какого множества выбирать скорости или углы при каждом вызове new_state?
По какому критерию выбирать одну конкретную траекторию из множества всех возможных в графе?


# Интеграция c++ кода в Unity
Поэтому на первом этапе нужно:
1.	создать плагин на с++ RRTPlanerPlugin,
2.	положить его в каталог Plugins проекта car_model.  Как описано в этом туториале.
3.	Посмотреть как работать с базовыми типа Unity такими как Vector3.
4.	Продумать как создавать обертки вокруг нативных классов. См. каталог wrapper_class
a.	(Здесь важно какой код создает и уничтожает обьект, управляемый или не управляемый)

# Преимущества нативного кода.
   Более высокая скорость выполнения. Пайтон и c# в этом смысле не очень

В каталоге Unity Projects\car_model\Assets\Plugins содержатся функции экспорта типов c# в c++ плагин.


## Тест распределения.

1.	Подключить TestDll к скрипту RttPlaner.cs и сделать один делегат GenerateCoordinates
2.	Подготовить тест в RttPlaner.cs тест будет отправлять в TestDll параметры распределения максимальные и минимальные значения для X и Z компоненты. На выходе c++ код сгенерирует два массива типа double с координатами
3.	Чтобы проверить правильность генерации координат можно создать сферы точечного размера в координатах из этих двух массивов


# Что мне не нравится в этой картинке?
 
Во первых траектория меняется слишком резко. Это предположительно изза того что функция steering имеет случайный характер (см. следующий заголовок)
Bторое есть дефекты в функции детектора коллизий.
Нам нужна функция сглаженного галсового шума с кубической сплайновой интерполяцией.
Тест функции управления рулем (steering_fun)
1.	Создать на c++ отдельное приложение с выводом графика функции для тестирования функции рулевого управления. В данный момент 03.06.20 в рамках rrt алгоритма и интегрирования траектории управление осуществляется случайной функцией с равномерным распределением (-max_steering, max_steering).
a.	Как вариант скачать или установить Qt и график qwt. Но только использовать среду visual studio вместо qtcreator.
b.	Написать скрипт на Питоне для построения графиков функций после dsp в консольном приложении car_model\TestCPPApp\TestCPPApp\plot_me.py.
c.	Выводить отчеты в файл и строить график в питоне.
2.	Перенести старый код, нам нужна функция сглаженного галсового шума с кубической сплайновой интерполяцией. Каждому пути в rrt должна соответствовать своя сглаженная функция steering_fun.. Отсчеты готовятся заранее в native коде.

Приложение TestCPPApp  использует TestDLL для вызова dsp функций генерирования сигналов steering. Эта же длл используется в Unity проекте car_model.

Модификация скрипта RrtPlaner.cs.
Присвоение к каждому пути уникального числа.
Подключение нативных функций по генерированию steering сигналов из TestDll


За последнее время начиная с сентября 2020 по 17.11.2020 были сделаны следующие изменения.
Можно сделать видео. Я установил ffmpeg на диск E в корне лежат батники для записи видео.
capture_audio_video_ffmpeg

# Сделать видеотутор по проекту. 
1. Загрузить проект BallMaze
2. Показать как работает компонент RRTPlaner
3. Показать лабораторию обучения
4. Показать как запускать обучение
5. Показать как работает обученный агент

Освоен пакет mlagents.
Заведен проект на github называется BallPark. Он содержит планировщик пути, лабиринт и пример тренировочной сессии для тренировки робота.

Сначала я пробовал написать свой сенсор, получалось обучить агента, но он не был таким хорошим как встроенный 3д сенсор. Возможно потом мне еще пригодятся наработки по своему сенсору. В частности возможно пригодится поощрение за правильное сканирование.

# Следующий этап
Можно сделать обучение агента наподобии CubeAgent проекта BallPark только с управлением моделью авто.
6 агнетов в 6 секциях как на рисунке.

![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/agents_learning_env.png)

# Плитки из miniRRT. Обучение CNN на большом количестве лабиринтов. 
Можно рабить все изображение лабиринта на большое количество мелких сегментов (квадратных элементов мозайки) 
Потом обучить нейросеть составлять RRT имея только изображение лабиринта (зеленые стены).
Пои идее это ускорнит алгоритм, поскольку не надо считать пересечения.
Можно пойти дальше и составить изображения всевозможных маневров, например для парковки.





Создать новый проект в Unity “caragent”
Загрузить модель авто из car_model. Возможно как prefarb.
![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/car_model_project2.png)

1 Генерируются тестовые препятствия.
2 Генерируются траектории с помощью RRTPlaner
3.Генерируются вейпоинты
Для каждой секции в каждом эпизоде обучения получается уникальный набор препятствий и траекторий. Агент поощряется если он проходит все вейпоинты и делает это быстро.
Пример тренировочной лаборатории для агента который учиться «врезаться» в условный вейпоинт

тот же самый агент едущий по траектории проложенной по лабиринту

Скриншоты 19.11.2020
![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/parking_slots.png)
![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/path_planer.png)
![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/trajectory.png)
![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/waypoints.png)

новый генератор обучающей среды для агента типа автомобиль, должно быть таких 6 сред.
доработанный планировщик пути (заменен Raycast на Spherecast) и изменено распределение в ддлке. Путь можно строить в реальном времени, выбирать оптимальную траекторию пощаще.

## Post statistical control
Идея постатистики состоит в том что сначала мы формируем некую статистику по траектории. После чего даем награду агенту если его движения соответсвует этой статистике т.е. дисперсия и мат отклонение.

это видео из ютьюба иллюстрирует данный концепт
[![image](https://github.com/Kvazikot/BallPark/blob/main/screenshots/poststatistical.png)](https://www.youtube.com/embed/b8YtXNklqpM)

## Литература:

1. Nonlinear Dynamics And Chaos With Applications To Physics, Biology, Chemistry, And Engineering by Steven H. Strogatz
2. Rapidly-Exploring Random Trees: Progress and Prospects
3. [Unity Machine Learning Agents](https://unity.com/products/machine-learning-agents)
